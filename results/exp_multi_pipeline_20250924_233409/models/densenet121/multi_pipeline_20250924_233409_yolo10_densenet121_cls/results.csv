epoch,train_loss,train_acc,val_loss,val_acc
1,0.850154,63.57,0.477741,95.96
2,0.311113,91.50,0.280238,94.39
3,0.276336,91.80,3.324819,92.15
4,0.326797,91.50,15.052655,63.45
5,0.385728,90.43,nan,95.96
6,0.518642,90.33,65.804052,0.90
7,0.455394,90.23,nan,95.96
8,0.363909,90.43,175.111872,95.96
9,0.350149,91.11,12.059484,96.41
10,0.361997,91.02,14.025590,74.22
11,0.432930,89.75,0.253643,95.96
12,0.370373,90.14,0.242332,96.41
13,0.363816,90.04,0.237599,96.64
14,0.313743,91.70,0.223805,96.41
15,0.321278,91.31,0.227790,96.19
16,0.300564,91.21,0.234280,95.96
17,0.303647,91.11,0.198958,96.41
18,0.289857,91.80,0.203646,96.86
19,0.286663,91.80,0.217967,96.19
20,0.295668,91.41,0.192037,96.41
21,0.275140,91.11,0.212258,96.41
22,0.293222,91.11,0.230075,96.19
23,0.263508,91.99,0.204841,96.64
24,0.274708,92.19,0.196281,96.41
25,0.249359,92.97,0.199867,96.19
26,0.270417,92.09,0.192358,96.41
27,0.247098,92.48,0.189765,96.64
28,0.252723,92.19,0.192699,96.41
29,0.265839,91.70,0.190071,96.64
30,0.238514,92.77,0.192160,96.64
