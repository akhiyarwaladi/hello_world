epoch,train_loss,train_acc,val_loss,val_acc
1,1.022685,56.93,0.749928,93.95
2,0.297482,91.89,0.231885,95.68
3,0.251687,92.97,1.844305,95.68
4,0.308715,91.02,6.894186,95.68
5,0.500104,90.23,nan,84.45
6,0.549399,90.82,nan,94.60
7,0.368995,90.23,270.624939,95.68
8,0.347341,90.72,17.159861,87.90
9,0.340840,90.72,0.964472,89.42
10,0.382376,89.75,0.685033,80.35
11,0.356148,90.04,0.668103,66.09
12,0.333682,90.43,0.791732,66.52
13,0.365366,90.04,0.315361,92.01
14,0.324795,90.53,0.225339,94.38
15,0.312107,90.92,0.215660,96.33
16,0.306561,91.11,0.190274,95.68
17,0.303322,90.14,0.215006,95.46
18,0.278368,91.11,0.181951,96.33
19,0.302603,91.02,0.217888,93.95
20,0.286660,91.50,0.182768,95.90
21,0.277799,91.50,0.187918,95.90
22,0.275119,91.41,0.173009,96.11
23,0.291044,91.41,0.191529,96.11
24,0.268023,91.89,0.173539,96.33
25,0.270349,91.41,0.171336,96.11
26,0.264494,91.31,0.170115,95.90
27,0.265623,91.89,0.174132,96.11
28,0.257307,92.09,0.174292,95.68
29,0.261003,91.80,0.174264,95.68
30,0.262644,91.89,0.173595,95.90
