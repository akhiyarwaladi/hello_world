epoch,train_loss,train_acc,val_loss,val_acc
1,0.534719,84.08,0.911445,95.96
2,0.260256,92.29,2.411150,95.96
3,0.282719,92.38,59.068636,95.96
4,0.359259,91.99,0.665658,92.83
5,0.324055,91.11,2.012596,90.81
6,0.373500,91.11,nan,95.96
7,0.419791,89.84,nan,95.96
8,0.399471,90.72,127.857463,93.72
9,0.374788,90.53,118.628517,95.96
10,0.390385,90.53,nan,95.96
11,0.388575,90.62,nan,13.90
12,0.361187,90.62,2.451405,78.70
13,0.369566,90.23,3.923015,84.53
14,0.358479,90.82,0.388342,95.96
15,0.310788,91.70,0.220082,96.19
16,0.315100,91.41,0.235290,96.41
17,0.296465,91.41,0.243519,95.74
18,0.289812,91.11,0.257900,95.96
19,0.292196,91.80,0.205158,96.64
20,0.280502,91.31,0.236723,96.41
21,0.247036,92.58,0.220079,96.19
22,0.282367,91.70,0.232189,96.41
23,0.264474,92.09,0.225270,96.64
24,0.243165,92.38,0.207281,96.41
25,0.270154,91.89,0.193015,96.86
26,0.255255,92.19,0.194960,96.64
27,0.273332,91.70,0.199496,96.41
28,0.259771,91.41,0.203055,96.19
29,0.242778,92.77,0.203111,96.19
30,0.259112,92.29,0.203278,96.19
