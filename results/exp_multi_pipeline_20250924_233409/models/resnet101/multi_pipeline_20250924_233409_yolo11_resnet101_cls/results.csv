epoch,train_loss,train_acc,val_loss,val_acc
1,0.595600,80.47,0.483067,95.68
2,0.275654,92.29,2.955147,95.68
3,0.299976,91.11,0.904883,95.68
4,0.254720,92.09,1.306126,62.63
5,0.522963,91.89,nan,75.16
6,0.448122,90.82,nan,92.44
7,0.605005,89.75,nan,95.68
8,0.503790,89.75,nan,95.68
9,0.463484,89.94,nan,95.68
10,0.384909,90.82,27.554213,95.25
11,0.399519,89.94,0.372018,95.25
12,0.398383,90.23,0.376777,94.17
13,0.372141,90.92,0.248157,95.68
14,0.363401,89.94,0.236592,95.68
15,0.349629,90.33,0.704828,95.68
16,0.368302,90.62,0.296436,95.68
17,0.339172,90.23,0.248301,95.68
18,0.324865,90.62,0.224368,95.90
19,0.317609,90.43,0.227055,95.68
20,0.323277,90.62,0.248800,95.68
21,0.315307,90.23,0.230817,95.25
22,0.296802,90.72,0.201900,95.25
23,0.300615,90.72,0.194635,95.25
24,0.280783,91.41,0.194023,95.46
25,0.286615,90.62,0.198221,95.25
26,0.283036,90.53,0.196005,95.25
27,0.285535,90.82,0.195434,95.25
28,0.266480,91.21,0.193527,95.25
29,0.300933,90.53,0.192588,95.25
30,0.260645,91.70,0.191624,95.25
