epoch,train_loss,train_acc,val_loss,val_acc
1,0.533132,84.77,0.744980,95.90
2,0.242771,92.29,3.930866,95.90
3,0.250860,93.26,9.058260,95.90
4,0.304806,91.31,0.556896,84.28
5,0.359927,91.02,237.384579,95.90
6,0.325703,91.50,nan,95.90
7,0.384257,90.33,nan,95.90
8,0.321906,91.11,12.818303,95.90
9,0.408501,91.02,nan,95.90
10,0.391395,90.53,2.841309,95.67
11,0.365966,91.02,1.101992,76.77
12,0.314909,91.60,7.600823,95.67
13,0.296008,91.41,1.936525,95.90
14,0.334907,91.02,0.694222,95.90
15,0.253119,91.99,0.506124,95.90
16,0.311376,91.80,0.313626,95.67
17,0.295797,91.80,0.258409,96.36
18,0.276040,91.80,0.330105,95.90
19,0.287436,90.62,0.342369,95.90
20,0.271730,90.92,0.343684,96.13
21,0.250360,92.29,0.292047,96.58
22,0.248943,92.58,0.257061,96.81
23,0.231091,92.77,0.269394,96.13
24,0.272013,91.21,0.234352,96.36
25,0.240189,92.58,0.242200,96.58
26,0.241427,92.58,0.237465,96.58
27,0.241253,91.80,0.245203,96.36
28,0.238770,91.99,0.242863,96.36
29,0.232469,92.68,0.237785,96.36
30,0.238631,92.58,0.237780,96.36
