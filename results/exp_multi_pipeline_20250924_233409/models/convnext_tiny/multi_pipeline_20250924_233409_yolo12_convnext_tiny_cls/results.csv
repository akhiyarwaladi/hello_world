epoch,train_loss,train_acc,val_loss,val_acc
1,0.614519,76.37,0.255829,95.90
2,0.313168,91.70,0.266471,95.67
3,0.263361,92.48,0.246134,96.36
4,0.394836,87.70,0.314156,95.90
5,0.804244,83.79,0.412580,95.90
6,0.405787,91.31,0.375165,95.90
7,0.407077,91.02,0.384647,95.90
8,0.386687,91.50,0.407387,95.90
9,0.414037,90.62,0.385729,95.90
10,0.400245,91.11,0.381768,95.90
11,0.382611,91.50,0.402681,95.90
12,0.392754,91.41,0.383350,95.90
13,0.395280,91.31,0.386952,95.90
14,0.396648,91.31,0.378770,95.90
15,0.387213,91.50,0.379445,95.90
16,0.378919,91.50,0.379933,95.90
17,0.390571,91.21,0.376558,95.90
18,0.394239,91.21,0.386546,95.90
19,0.396497,91.02,0.376466,95.90
20,0.380001,91.50,0.375849,95.90
21,0.393970,91.11,0.380086,95.90
22,0.384281,91.41,0.377833,95.90
23,0.386287,91.31,0.377525,95.90
24,0.388893,91.21,0.376484,95.90
25,0.391616,91.11,0.378252,95.90
26,0.385880,91.31,0.378303,95.90
27,0.395464,91.02,0.378211,95.90
28,0.390476,91.11,0.377754,95.90
29,0.383758,91.31,0.377602,95.90
30,0.391150,91.11,0.377600,95.90
