epoch,train_loss,train_acc,val_loss,val_acc
1,0.623569,75.39,0.232172,95.96
2,0.350853,90.82,0.304841,95.96
3,0.382331,90.53,0.261816,95.96
4,0.550794,84.38,0.460805,95.96
5,0.429223,90.33,0.351993,95.96
6,0.407113,90.53,0.321045,95.96
7,0.396032,90.43,0.295650,95.96
8,0.377670,90.92,0.355203,95.96
9,0.393462,90.53,0.351930,95.96
10,0.383136,90.62,0.332684,95.96
11,0.366334,90.92,0.266250,95.96
12,0.362209,91.41,0.269234,95.96
13,0.374135,90.62,0.295142,95.96
14,0.370776,90.33,0.312019,95.96
15,0.383185,90.43,0.286295,95.96
16,0.365936,90.04,0.277917,95.96
17,0.348859,90.82,0.266871,95.96
18,0.318531,91.31,0.278080,95.96
19,0.345872,90.82,0.255351,95.96
20,0.336942,90.72,0.269964,95.96
21,0.331432,91.02,0.258806,95.96
22,0.344555,90.62,0.241834,96.19
23,0.346904,90.62,0.253913,95.74
24,0.343053,90.82,0.249826,95.74
25,0.332764,90.72,0.251399,95.96
26,0.312171,91.21,0.250252,95.74
27,0.329582,90.82,0.247098,95.74
28,0.332506,91.02,0.244257,95.96
29,0.331887,91.02,0.243913,95.96
30,0.322518,91.31,0.243838,95.96
