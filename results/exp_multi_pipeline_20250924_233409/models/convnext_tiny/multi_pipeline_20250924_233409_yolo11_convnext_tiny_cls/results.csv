epoch,train_loss,train_acc,val_loss,val_acc
1,0.651799,78.32,0.310197,95.68
2,0.453044,90.23,0.338110,95.68
3,0.410623,89.94,0.380463,95.68
4,0.415457,89.84,0.300930,95.68
5,0.451901,90.43,0.424995,95.68
6,0.442134,91.02,0.364315,95.68
7,0.428828,90.82,0.327489,95.68
8,0.414550,90.82,0.326057,95.68
9,0.434385,90.43,0.316735,95.68
10,0.431419,90.43,0.320598,95.68
11,0.439575,90.14,0.312100,95.68
12,0.427322,90.33,0.311128,95.68
13,0.429388,90.43,0.322689,95.68
14,0.412902,90.62,0.315327,95.68
15,0.443983,89.94,0.312826,95.68
16,0.442163,89.84,0.307495,95.68
17,0.404479,91.11,0.318537,95.68
18,0.401458,91.02,0.308618,95.68
19,0.419941,90.43,0.318283,95.68
20,0.395700,91.11,0.309705,95.68
21,0.417846,90.53,0.311766,95.68
22,0.414672,90.53,0.312686,95.68
23,0.425108,90.23,0.317789,95.68
24,0.405006,90.82,0.313035,95.68
25,0.416681,90.53,0.311099,95.68
26,0.408565,90.72,0.312764,95.68
27,0.417715,90.43,0.312755,95.68
28,0.428472,90.14,0.313412,95.68
29,0.402324,90.92,0.313637,95.68
30,0.405914,90.82,0.313637,95.68
