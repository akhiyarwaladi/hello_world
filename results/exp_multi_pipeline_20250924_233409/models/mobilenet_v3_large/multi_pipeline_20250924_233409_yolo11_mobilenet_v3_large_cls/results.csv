epoch,train_loss,train_acc,val_loss,val_acc
1,0.557720,81.64,0.334117,94.17
2,0.266799,92.19,0.239538,95.46
3,0.189424,94.04,0.381226,95.68
4,0.222188,92.19,0.570993,95.46
5,0.271345,91.99,5.562648,95.68
6,0.363629,91.02,10.780021,95.68
7,0.539176,87.99,625.506317,9.07
8,0.668862,85.06,nan,95.68
9,2.820449,66.99,nan,95.68
10,2.988331,87.30,nan,95.68
11,3.272062,68.26,nan,95.68
12,1.796068,78.03,nan,95.68
13,3.223919,84.77,nan,95.68
14,4.144469,74.51,nan,95.68
15,2.116449,88.87,nan,95.68
16,0.988784,84.57,nan,95.68
17,0.535943,89.45,nan,95.68
18,0.532237,89.16,70.560921,95.68
19,0.478195,89.45,24.628561,95.68
20,0.401461,90.14,9.226859,95.68
21,0.394999,89.94,4.103156,95.68
22,0.383484,90.33,2.087440,95.68
23,0.375135,90.43,2.186660,95.68
24,0.358245,90.53,1.610726,95.68
25,0.364671,90.23,1.223020,95.68
26,0.344388,90.82,1.091297,95.68
27,0.333658,90.82,0.987649,95.68
28,0.319708,91.11,0.902438,95.68
29,0.335793,90.92,0.834151,95.68
30,0.329907,91.31,0.775779,95.68
